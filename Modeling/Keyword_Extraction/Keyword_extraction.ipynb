{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "municipal-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 22.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from wordcloud) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from wordcloud) (1.19.5)\n",
      "Requirement already satisfied: pillow in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from wordcloud) (8.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suspected-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incredible-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('News_s20230601.csv',dtype= {'press_id': 'object', 'section_id': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "willing-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식으로 한글만 필터링\n",
    "import re\n",
    "\n",
    "def text_cleaning(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "    \n",
    "    result = hangul.sub('', text)\n",
    "    return result\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x : text_cleaning(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "understood-charlotte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오신환 서울시 전 정무부시장이 일 서울시의 경계경보 발령 논란에 대해 오발령 공지를 한 행정안전부를 겨냥해 그럴 여유가 있었다면 서울시와 좀 더 소통해서 서울시가 직접 정정 또는 해제하도록 권고하는 게 오히려 바람직한 결과를 낳았을 것이라고 비판했다'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.compile('[^ ㄱ-ㅣ가-힣]+').sub('',df['content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "russian-update",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [오신, 오신환, 환, 서울시, 전, 정무, 정무부시, 부시, 일, 경계, 경계경보...\n",
       "1     [부산, 벡스코, 국제, 국제해양방위산업, 해양, 방위, 산업, 전은, 정부, 세계...\n",
       "2     [인천시, 중구, 동구, 통합, 제물, 제물포구, 포구, 신설, 영종, 영종도, 도...\n",
       "3     [종, 국방부, 장관, 일, 국회, 열린, 국방위, 전체, 전체회의, 회의, 북한,...\n",
       "4     [유, 유승민, 승, 민, 전, 의원, 일, 사회, 사회관계망서비스, 관계, 망, ...\n",
       "5     [합동, 합동참모본부, 참모, 본부, 일, 어청도, 서방, 여, 해상, 인양, 북,...\n",
       "6     [종, 국방부, 장관, 일, 국회, 국방, 국방위원회, 위원회, 전체, 전체회의, ...\n",
       "7     [김, 김기현, 기현, 국민, 힘, 대표, 일, 경기, 경기도, 도, 수원, 경기도...\n",
       "8     [국민, 힘, 급, 당직자, 씨, 강원, 강원도, 강원도당, 도, 당, 근무, 직원...\n",
       "9     [해, 해사안전위원회, 사, 안전, 위원회, 일, 영국, 런던, 본부, 제차, 회의...\n",
       "10    [민주당, 탈당, 무소속, 부천, 부천시의회, 시의회, 박성호, 의원, 일, 임시회...\n",
       "11    [지난달, 일, 북한, 평안북, 평안북도, 도, 철산군, 동창, 새, 새발사장, 발...\n",
       "12    [국방, 국방과학연구소국과, 과학, 연구소, 국과, 연, 흥, 종합, 종합시험장, ...\n",
       "13    [이재명, 민주당, 대표, 일, 사회, 사회관계망서비스, 관계, 망, 서비스, 경찰...\n",
       "14    [조, 조현동, 현동, 주미, 한국, 한국대사, 대사, 일, 일현지시간, 현지, 시...\n",
       "15    [일, 오전, 해군, 해경, 국방부, 직할, 국군, 국군화생방방호사령부, 화생방, ...\n",
       "16    [국회, 국방, 국방위원회, 위원회, 일, 오전, 시, 전체, 전체회의, 회의, 북...\n",
       "17    [김, 북한, 국무, 국무위원장, 위원장, 여동생, 김여정, 여정, 노동당, 부부,...\n",
       "18    [후, 원전, 오염, 오염수, 수, 현장, 시찰단, 단장, 유, 유국희, 국희, 원...\n",
       "19    [월, 온라인, 온라인쇼핑, 쇼핑, 거래액, 전년, 동, 동월, 월, 대비, 조, ...\n",
       "20    [네이버, 사용자, 보호, 게시물, 혐오, 표현, 구체화, 운영, 정책, 해당, 삭...\n",
       "21    [부영, 부영그룹, 그룹, 정, 주년, 공군, 하늘, 하늘사랑, 사랑, 장학, 장학...\n",
       "22    [신한, 신한은행, 은행, 외환, 관련, 전산, 전산시스템, 시스템, 오류, 발생,...\n",
       "23    [한국, 한국부동산원, 부동산, 원, 월, 주일, 기준, 전국, 주간, 아파트, 가...\n",
       "24    [금융, 금융감독원, 감독원, 저축, 저축은행중앙회, 은행, 중앙회, 일, 저축은행...\n",
       "25    [새, 금, 이차, 이차전지, 전지, 특화, 특화단지, 단지, 유치, 전, 전북도,...\n",
       "26    [디지털, 디지털자산거래소, 자산, 거래소, 공동, 공동협의체닥사, 협의체, 닥, ...\n",
       "27    [공정위, 스마트, 스마트태그, 태그, 시스템, 프로젝트, 진행, 하도급, 업체, ...\n",
       "28    [엔터테인먼트, 소속, 아티스트, 전속, 계약, 해지, 통보, 주가, 급락, 이, ...\n",
       "29    [대우, 대우건설, 건설, 서울, 관악, 관악구, 구, 신림, 신림동, 동, 번지,...\n",
       "30    [롯데, 롯데건설, 건설, 서울, 동대문, 동대문구, 구, 청량리, 청량리구역, 구...\n",
       "31    [하나, 하나금융그룹, 금융, 그룹, 일, 미래, 셋, 셋증권, 증권, 토큰, 토큰...\n",
       "32    [손해, 손해보험, 보험, 핵심, 보장, 치료비, 비율, 최대, 확대, 자기, 자기...\n",
       "33    [행정, 행정안전부, 안전, 부, 지난달, 일, 서울시, 북한, 발사체, 관련, 발...\n",
       "34    [지난달, 일, 건강, 건강보험공단, 보험, 공단, 상대, 재판, 승소, 지, 소성...\n",
       "35    [서울, 서울중앙지검, 중앙, 지검, 공공, 공공수사부부장검사, 수사부, 부장, 검...\n",
       "36    [네이버, 사용자, 보호, 게시물, 혐오, 표현, 구체화, 운영, 정책, 해당, 삭...\n",
       "37    [부산, 벡스코, 국제, 국제해양방위산업, 해양, 방위, 산업, 전은, 정부, 세계...\n",
       "38    [인천시, 중구, 동구, 통합, 제물, 제물포구, 포구, 신설, 영종, 영종도, 도...\n",
       "39    [전, 전북대병원, 북대, 병원, 겸직, 겸직허가, 허가, 요청, 전문의, 전문의위...\n",
       "40    [새, 금, 이차, 이차전지, 전지, 특화, 특화단지, 단지, 유치, 전, 전북도,...\n",
       "41    [지난해, 월일, 지하, 층, 화재, 발생, 환경, 환경미화시설관리, 미화, 시설,...\n",
       "42    [부산, 부산경찰청, 경찰청, 부산금정경찰, 금정, 경찰, 과외, 연결, 플랫폼, ...\n",
       "43    [경기, 경기남부경찰청, 남부, 경찰청, 부패, 부패경제범죄수사대, 경제, 범죄, ...\n",
       "44    [국가, 국가인권위원회, 인권, 위원회, 지난달, 일, 인천, 정신, 정신의료기관,...\n",
       "45    [한국, 한국여성정책연구원, 여성, 정책, 연구원, 한국리서치, 리서치, 만, 세,...\n",
       "46    [국가, 국가인권위원회, 인권, 위원회, 공황, 공황장애, 장애, 진단, 정기적, ...\n",
       "47    [유, 유승민, 승, 민, 전, 의원, 일, 사회, 사회관계망서비스, 관계, 망, ...\n",
       "48    [년, 총선, 총선대, 대, 때, 정치, 정치자금, 자금, 만원, 뒤, 선거, 선거...\n",
       "49    [지난달, 일, 일현지시간, 현지, 시간, 보고서, 통, 의, 농축, 우라늄, 비축...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma = konlpy.tag.Kkma() #형태소 분석기 꼬꼬마(Kkma)\n",
    "\n",
    "nouns = df['content'][:50].apply(kkma.nouns)\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "catholic-sudan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      오신\n",
       "0     오신환\n",
       "0       환\n",
       "0     서울시\n",
       "0       전\n",
       "     ... \n",
       "49      핵\n",
       "49    핵합의\n",
       "49     합의\n",
       "49     복원\n",
       "49     전망\n",
       "Name: content, Length: 1661, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = nouns.explode()\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "extensive-observer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      오신\n",
       "0     오신환\n",
       "0       환\n",
       "0     서울시\n",
       "0       전\n",
       "     ... \n",
       "49      핵\n",
       "49    핵합의\n",
       "49     합의\n",
       "49     복원\n",
       "49     전망\n",
       "Name: word, Length: 1661, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bibliographic-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = pd.DataFrame({'word' : nouns})\n",
    "df_word['count'] = df_word['word'].str.len()\n",
    "#df_word = df_word.query('count >= 2')\n",
    "#df_word.sort_values(by= ['count'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "animated-forge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>발사</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>미국</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>북한</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>시간</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>국민</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>비금면</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>비금</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>비교</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>비공개</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>희석</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1343 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  count\n",
       "412    발사     12\n",
       "392    미국     12\n",
       "483    북한     12\n",
       "640    시간      9\n",
       "159    국민      8\n",
       "...   ...    ...\n",
       "505   비금면      1\n",
       "504    비금      1\n",
       "503    비교      1\n",
       "502   비공개      1\n",
       "1342   희석      1\n",
       "\n",
       "[1343 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word = df_word.groupby('word', as_index = False).count().sort_values(by= ['count'], ascending = False)\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fundamental-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어제거\n",
    "df_word.sort_values(by = ['count'], ascending = False)\n",
    "\n",
    "okt = Okt()\n",
    "stop_words = sw\n",
    "\n",
    "result =[]\n",
    "for i in range(len(df_word['word'])):\n",
    "    txt = df_word['word'][i]\n",
    "    stop_words = set(stop_words)\n",
    "    word_tokens = okt.morphs(txt)\n",
    "    result += [word for word in word_tokens if not word in stop_words]\n",
    "\n",
    "result\n",
    "df_word = df_word[(df_word['word'].isin(result))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ignored-injection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1023 entries, 412 to 502\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   word    1023 non-null   object\n",
      " 1   count   1023 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_word.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-channel",
   "metadata": {},
   "source": [
    "## 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "better-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_word = df_word.set_index('word').to_dict()['count']\n",
    "# dic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "collect-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw = pd.read_csv('stopwords.csv',encoding= 'utf-8')\n",
    "# sw = sw['불용어']\n",
    "# sw.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "juvenile-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# okt = Okt()\n",
    "\n",
    "# example = \"휴 아이고 아이쿠 아홉\"\n",
    "# stop_words = sw\n",
    "\n",
    "# stop_words = set(stop_words)\n",
    "# word_tokens = okt.morphs(example)\n",
    "\n",
    "# result = [word for word in word_tokens if not word in stop_words]\n",
    "\n",
    "# print('불용어 제거 전 :',word_tokens) \n",
    "# print('불용어 제거 후 :',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "speaking-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wc = WordCloud(random_state = 123, font_path = '/usr/share/fonts/truetype.ttf', width = 400,height = 400, background_color = 'white')\n",
    "\n",
    "# img_wordcloud = wc.generate_from_frequencies(dic_word)\n",
    "\n",
    "# plt.figure(figsize = (10, 10)) # 크기 지정하기\n",
    "# plt.axis('off') # 축 없애기\n",
    "# #plt.imshow(img_wordcloud) # 결과 보여주기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "framed-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_csv('News_20230601.csv',dtype= {'press_id': 'object', 'section_id': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "honey-oxford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>headline</th>\n",
       "      <th>writer</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>created_date</th>\n",
       "      <th>press_id</th>\n",
       "      <th>section_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>459</td>\n",
       "      <td>“尹대통령과 커피 마시는 꿈 꾸고 대박”…복권 1등 당첨된 여성 사연 보니</td>\n",
       "      <td>김수연 기자</td>\n",
       "      <td>https://n.news.naver.com/article/022/000381865...</td>\n",
       "      <td>‘스피또 1000’ 제71회 복권 당첨 사연 공개돼    동행복권 홈페이지 갈무리 ...</td>\n",
       "      <td>2023-06-01 11:21:07</td>\n",
       "      <td>022</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                   headline  writer  \\\n",
       "453  459  “尹대통령과 커피 마시는 꿈 꾸고 대박”…복권 1등 당첨된 여성 사연 보니  김수연 기자   \n",
       "\n",
       "                                                   url  \\\n",
       "453  https://n.news.naver.com/article/022/000381865...   \n",
       "\n",
       "                                               content         created_date  \\\n",
       "453  ‘스피또 1000’ 제71회 복권 당첨 사연 공개돼    동행복권 홈페이지 갈무리 ...  2023-06-01 11:21:07   \n",
       "\n",
       "    press_id section_id  \n",
       "453      022        102  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[d['headline'] =='“尹대통령과 커피 마시는 꿈 꾸고 대박”…복권 1등 당첨된 여성 사연 보니']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exterior-floor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‘스피또 1000’ 제71회 복권 당첨 사연 공개돼    동행복권 홈페이지 갈무리    \\xa0  윤석열 대통령과 커피를 마시는 꿈을 꾼 뒤 복권 1등에 당첨됐다는 여성의 사연이 공개됐다.  \\xa0  1일 동행복권에 따르면 경기 용인시의 한 복권판매점에서 ‘스피또 1000’ 제71회 복권을 구입한 A씨가\\xa0최근 해당 복권 1등에 당첨돼 5억원을 수령했다.  \\xa0  A씨는 “평소 재미 삼아 로또와 스피또 복권을 구매해왔다”며 “최근 윤 대통령과 커피 마시는 꿈을 꿨고, 그 기운을 받아 당첨복권 12장을 교환하러 집 주변에 있는 복권판매점에 방문했다”고 운을 뗐다.  \\xa0  그는 “처음 방문한 판매점에서는 스피또1000 복권이 소진돼서 교환할 수 없었다”며 “두 번째로 간 판매점에 10장이 남아 있어서 10장만 교환했다. 세 번째 판매점에서 남은 2장을 교환하고 집으로 돌아왔다”고 설명했다.  \\xa0  이어 “두 번째 판매점에서 교환한 10장을 다 긁고 마지막 남은 2장을 긁었는데, 5억원이 당첨됐다”며 “남편은 농담하지 말라고 하더라. 처음에는 얼떨떨하고 믿기지 않았는데, 고객센터에 당첨 확인과 방문 예약을 하니 실감이 났다”고 전했다.  \\xa0  그러면서 “최근 스피또1000 2등에도 당첨돼서 올해 기운이 좋다고 생각했는데, 1등까지 당첨돼서 기분이 너무 좋”\"며 “신종 코로나바이러스 감염증(코로나19) 이후 사업을 정리하고 쉬고 있었는데 큰 도움이 될 것 같다”고 당첨 소감을 밝혔다.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['content'][453]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "green-seeking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 개수: 273\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "def count_tokens_korean(word):\n",
    "    tokenizer = MeCab.Tagger()\n",
    "    tokens = tokenizer.parse(word).split(\"\\n\")\n",
    "    token_count = len(tokens) - 2  # EOS, 끝의 빈 줄을 제외\n",
    "    return token_count\n",
    "\n",
    "word = '''\n",
    "경기 용인시의 한 복권판매점에서 ‘스피또 1000’ 제71회 복권을 구입한 A씨가 최근 윤 대통령과 커피 마시는 꿈을 꾼 뒤 당첨복권 12장을 교환하러 집 주변에 있는 복권판매점에 방문하여 당첨돼 5억원을 수령했다고 밝혔다. A씨는 “평소 재미 삼아 로또와 스피또 복권을 구매해왔다”며 “최근 윤 대통령과 커피 마시는 꿈을 꿨고, 그 기운을 받아 당첨복권 12장을 교환하러 집 주변에 있는 복권판매점에 방문했다”고 운을 뗐다. 그는 “처음 방문한 판매점에서는 스피또1000 복권이 소진돼서 교환할 수 없었다”며 “두 번째로 간 판매점에 10장이 남아 있어서 10장만 교환했다. 세 번째 판매점에서 남은 2장을 교환하고 집으로 돌아왔다”고 설명했다. 이어 “두 번째 판매점에서 교환한 10장을 다 긁고 마지막 남은 2장을 긁었는데, 5억원이 당첨됐다”며 “남편은 농담하지 말라고 하더라. 처음에는 얼떨떨하고 믿기지 않았는데, 고객센터에 당첨 확인과 방문 예약을 하니 실감이 났다”고 전했다.'''\n",
    "token_count = count_tokens_korean(word)\n",
    "print(f\"토큰 개수: {token_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "becoming-marriage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['안녕\\tIC,*,T,안녕,*,*,*,*',\n",
       " '반가워\\tVA+EC,*,F,반가워,Inflect,VA,EC,반갑/VA/*+어/EC/*',\n",
       " '다시\\tMAG,성분부사|시간부사,F,다시,*,*,*,*',\n",
       " '만나\\tVV,*,F,만나,*,*,*,*',\n",
       " '자\\tEC,*,F,자,*,*,*,*',\n",
       " 'EOS',\n",
       " '']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = MeCab.Tagger()\n",
    "tokens = tokenizer.parse('안녕 반가워 다시만나자').split(\"\\n\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "infectious-sunset",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'경기 용인시의 한 복권판매점에서 ‘스피또 1000’ 제71회 복권을 구입한 A씨가 최근 윤 대통령과 커피 마시는 꿈을 꾼 뒤 당첨복권 12장을 교환하러 집 주변에 있는 복권판매점에 방문했다고 밝혔다.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "##3. 토크나이저 및 모델 로드\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-summarization')\n",
    "\n",
    "\n",
    "##4. GPU 사용가능 여부 확인 및 Device 설정\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # GPU를 디바이스로 설정\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    # CPU를 디바이스로 설정\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "## 5. 모델적용\n",
    "today = str(datetime.today().strftime(\"%Y%m%d\"))\n",
    "max_length = 512  # 최대 토큰 수\n",
    "\n",
    "text = '''\n",
    "‘스피또 1000’ 제71회 복권 당첨 사연 공개돼    동행복권 홈페이지 갈무리    \\xa0  윤석열 대통령과 커피를 마시는 꿈을 꾼 뒤 복권 1등에 당첨됐다는 여성의 사연이 공개됐다.  \\xa0  1일 동행복권에 따르면 경기 용인시의 한 복권판매점에서 ‘스피또 1000’ 제71회 복권을 구입한 A씨가\\xa0최근 해당 복권 1등에 당첨돼 5억원을 수령했다.  \\xa0  A씨는 “평소 재미 삼아 로또와 스피또 복권을 구매해왔다”며 “최근 윤 대통령과 커피 마시는 꿈을 꿨고, 그 기운을 받아 당첨복권 12장을 교환하러 집 주변에 있는 복권판매점에 방문했다”고 운을 뗐다.  \\xa0  그는 “처음 방문한 판매점에서는 스피또1000 복권이 소진돼서 교환할 수 없었다”며 “두 번째로 간 판매점에 10장이 남아 있어서 10장만 교환했다. 세 번째 판매점에서 남은 2장을 교환하고 집으로 돌아왔다”고 설명했다.  \\xa0  이어 “두 번째 판매점에서 교환한 10장을 다 긁고 마지막 남은 2장을 긁었는데, 5억원이 당첨됐다”며 “남편은 농담하지 말라고 하더라. 처음에는 얼떨떨하고 믿기지 않았는데, 고객센터에 당첨 확인과 방문 예약을 하니 실감이 났다”고 전했다.  \\xa0  그러면서 “최근 스피또1000 2등에도 당첨돼서 올해 기운이 좋다고 생각했는데, 1등까지 당첨돼서 기분이 너무 좋”\"며 “신종 코로나바이러스 감염증(코로나19) 이후 사업을 정리하고 쉬고 있었는데 큰 도움이 될 것 같다”고 당첨 소감을 밝혔다.\n",
    "'''\n",
    "text = text.replace('\\n', ' ')\n",
    "model.to(device)\n",
    "raw_input_ids = tokenizer.encode(str(text))\n",
    "input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "# 입력 문장 길이 제한\n",
    "if len(input_ids) > max_length:\n",
    "    input_ids = input_ids[:max_length]\n",
    "\n",
    "summary_ids = model.generate(torch.tensor([input_ids]).to(device), repetition_penalty=2.0, num_beams=4, \n",
    "                             min_length = 50, max_length=250,  eos_token_id=1)\n",
    "summary_news = tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "\n",
    "summary_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outside-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "e = pd.read_csv('News_s20230601.csv',dtype= {'press_id': 'object', 'section_id': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "negative-defensive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>headline</th>\n",
       "      <th>writer</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>created_date</th>\n",
       "      <th>press_id</th>\n",
       "      <th>section_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, headline, writer, url, content, created_date, press_id, section_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[e['section_id']== '110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-argument",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3] *",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
